:scrollbar:
:data-uri:
:toc2:
:imagesdir: images

= High Availability add-on on RHEL - LTO Show & Tell Series

== Description
This Show&Tell is aimed to share some of the most important concepts and features of the High Availability posibilities RHEL propose.

Audience: IT Managers, Architects and technical staff who operates Linux

:numbered:

== Introduction

The High Availability Add-On is a clustered system that provides reliability, scalability, and availability to critical production services.

A cluster is two or more computers (called nodes or members) that work together to perform a task. Clusters can be used to provide highly available services or resources. The redundancy of multiple machines is used to guard against failures of many types.

== Components

Mayor components are listed below:

* Cluster infrastructure — Provides fundamental functions for nodes to work together as a cluster: configuration file management, membership management, lock management, and fencing.
* High availability service management — Provides failover of services from one cluster node to another in case a node becomes inoperative.
* Cluster administration tools — Configuration and management tools for setting up, configuring, and managing the High Availability Add-On. The tools are for use with the cluster infrastructure components, the high availability and service management components, and storage.

Some supplements can be used for the High Availability Add-On with the following components:

* Red Hat GFS2 (Global File System 2) — Part of the Resilient Storage Add-On, this provides a cluster file system for use with the High Availability Add-On. GFS2 allows multiple nodes to share storage at a block level as if the storage were connected locally to each cluster node. GFS2 cluster file system requires a cluster infrastructure.
* LVM Locking Daemon (lvmlockd) — Part of the Resilient Storage Add-On, this provides volume management of cluster storage. lvmlockd support also requires cluster infrastructure.
* Load Balancer Add-On — Routing software that provides high availability load balancing and failover in layer 4 (TCP) and layer 7 (HTTP, HTTPS) services. The Load Balancer Add-On runs in a cluster of redundant virtual routers that uses load algorithms to distribute client requests to real servers, collectively acting as a virtual server. It is not necessary to use the Load Balancer Add-On in conjunction with Pacemaker.

=== Pacemaker

Pacemaker is a cluster resource manager. It achieves maximum availability for our cluster services and resources by making use of the cluster infrastructure’s messaging and membership capabilities to deter and recover from node and resource-level failure.

==== Pacemaker components

* Cluster Information Base (CIB)
The Pacemaker information daemon, which uses XML internally to distribute and synchronize current configuration and status information from the Designated Coordinator (DC) — a node assigned by Pacemaker to store and distribute cluster state and actions by means of the CIB — to all other cluster nodes.

* Cluster Resource Management Daemon (CRMd)
Pacemaker cluster resource actions are routed through this daemon. Resources managed by CRMd can be queried by client systems, moved, instantiated, and changed when needed.

Each cluster node also includes a local resource manager daemon (LRMd) that acts as an interface between CRMd and resources. LRMd passes commands from CRMd to agents, such as starting and stopping and relaying status information.

* Shoot the Other Node in the Head (STONITH)
STONITH is the Pacemaker fencing implementation. It acts as a cluster resource in Pacemaker that processes fence requests, forcefully shutting down nodes and removing them from the cluster to ensure data integrity. STONITH is configured in the CIB and can be monitored as a normal cluster resource. 

* corosync
corosync is the component - and a daemon of the same name - that serves the core membership and member-communication needs for high availability clusters. It is required for the High Availability Add-On to function.

Other corosync functions are:

- Manages quorum rules and determination.
- Provides messaging capabilities for applications that coordinate or operate across multiple members of the cluster and thus must communicate stateful or other information - between instances.
- Uses the kronosnet library as its network transport to provide multiple redundant links and automatic failover.

=== The fencing mechanism

If communication with a single node in the cluster fails, then other nodes in the cluster must be able to restrict or release access to resources that the failed cluster node may have access to. Because the node itself may not be responsive this cannot be accomplished by contacting the cluster failed node. Instead, we must provide an external method, which is called fencing with a fence agent. A fence device is an external device that can be used by the cluster to restrict access to shared resources by an errant node, or to issue a hard reboot on the cluster node.

=== The Quorum Mechanism

In order to maintain cluster integrity and availability, cluster systems use a concept known as quorum to prevent data corruption and loss. A cluster has quorum when more than half of the cluster nodes are online. To mitigate the chance of data corruption due to failure, Pacemaker by default stops all resources if the cluster does not have quorum.

Quorum is established using a voting system. When a cluster node does not function as it should or loses communication with the rest of the cluster, the majority working nodes can vote to isolate and, if needed, fence the node for servicing.

The quorum features in Pacemaker prevent what is also known as split-brain, a phenomenon where the cluster is separated from communication but each part continues working as separate clusters, potentially writing to the same data and possibly causing corruption or loss. 

A Red Hat Enterprise Linux High Availability Add-On cluster uses the votequorum service, in conjunction with fencing, to avoid split brain situations. A number of votes is assigned to each system in the cluster, and cluster operations are allowed to proceed only when a majority of votes is present.

=== What is a Resource?

An instance of program, data, or application to be managed by the cluster service is called A cluster resource. Agents abtracts these resources providing a standard interface for managing the resource in a cluster environment.

We can add monitoring operations to a resource’s definition to ensure that resources remain healthy. 

The behavior of a resource in a cluster can be determined by configuring constraints. 

* location constraints — A location constraint determines which nodes a resource can run on.
* ordering constraints — An ordering constraint determines the order in which the resources run.
* colocation constraints — A colocation constraint determines where resources will be placed relative to other resources.

Also, groups can be configured for setting resources that need to be located together, start sequentially, and stop in the reverse order.

* Logical volumes 

The Red Hat High Availability Add-On provides support for LVM volumes in two distinct cluster configurations:

* High availability LVM volumes (HA-LVM) in active/passive failover configurations in which only a single node of the cluster accesses the storage at any one time.
* LVM volumes that use the lvmlockd daemon to manage storage devices in active/active configurations in which more than one node of the cluster requires access to the storage at the same time. The lvmlockd daemon is part of the Resilient Storage Add-On.

=== A general diagram of a cluster implemented

image::cluster_depicted.png[]

== A practical HA implementation

In the next procedure we are going implement a simple web service on 3 nodes. This service will be in charge to serve a web page with apache and the content of this page is going to be stored in a shared iscsi storage. Simple, no?... let's get our hands dirty.

=== Some conventions for the rest of this document.

Let's assume the following server layout.

ha1.test.com -> node 1
ha2.test.com -> node 2
ha3.test.com- > node 3
str.test.com -> iscsi target

Every procedure explained in the next sections will have a scope of action that we are going describe with a tag and the scope. 

TAG [scope]

For example if we need to execute a command or procedure on ha1 server, the scope should look like this.

In which Server[ha1]

Or, if we need to execute a command on all servers of the cluster the tag should be represented by:

In which server[cluster]

Where cluster is comprised of ha1.test.com, ha2.test.com and ha3.test.com

So, you get my idea of the scoping.

=== Creating trust among servers
In which servers: [ALL]

Let's create a circle of trust for having SSH passwordless channels between servers.

As root, let's get access to each server and execute the following sequence.

In each server execute the following sequence.

[source, bash]
------------------------
ssh-keygen
for node in ha1 ha2 ha3 str; do ssh-copy-id $node; done
------------------------

=== Defining the naming convention in /etc/hosts
In which nodes: [ALL]

Change the IPs accordingly your servers are configured. 

Logged-in in the str.test.com server we can configure /etc/hosts as follow. First modify /etc/host in str.test.com.

[source, bash]
------------------------
cat <<EOF >> /etc/hosts
192.168.56.154 ha1.test.com ha1
192.168.56.160 ha2.test.com ha2
192.168.56.159 ha3.test.com ha3
192.168.56.157 str.test.com str
EOF
------------------------

Then, modify all the cluster node members accessing every node:

[source, bash]
------------------------
ssh ha1

cat <<EOF >> /etc/hosts 
192.168.56.154 ha1.test.com ha1 
192.168.56.160 ha2.test.com ha2 
192.168.56.159 ha3.test.com ha3 
192.168.56.157 str.test.com str 
EOF

ssh ha2
...
------------------------

We can chack what we just do it by executing the following from str:
[source, bash]
------------------------
for node in ha1 ha2 ha3; do \
echo $node; \
ssh $node cat /etc/hosts; \
done
------------------------

=== Configure the iscsi target server

We need an entity that shares a storage for this excercise. One easy way to do it is setting a server to serve an iscsi volume, which precisely is what we are going to do in the following simple steps.

So, our server is called str.test.com. Is a regular RHEL 8.2 server installed with all defaults. We have to install the software needed for enable this node to serve a volume using the iscsi protocol.

==== Installing the software
In which server[str.test.com]

Get access to the server via ssh then become root or use "sudo" for all the commands that are described below.

[source, bash]
------------------------
yum install -y targetcli


Updating Subscription Management repositories.
Red Hat Enterprise Linux 8 for x86_64 - AppStream (RPMs)                         726 kB/s |  19 MB     00:27
Red Hat Enterprise Linux 8 for x86_64 - BaseOS (RPMs)                            815 kB/s |  22 MB     00:27
Dependencies resolved.
=================================================================================================================
 Package                    Architecture  Version                  Repository                               Size
=================================================================================================================
Installing:
 targetcli                  noarch        2.1.51-4.el8_2           rhel-8-for-x86_64-appstream-rpms         79 k
Installing dependencies:
 python3-configshell        noarch        1:1.1.27-1.el8           rhel-8-for-x86_64-baseos-rpms            74 k
 python3-kmod               x86_64        0.9-20.el8               rhel-8-for-x86_64-baseos-rpms            90 k
 python3-pyparsing          noarch        2.1.10-7.el8             rhel-8-for-x86_64-baseos-rpms           142 k
 python3-rtslib             noarch        2.1.71-4.el8             rhel-8-for-x86_64-baseos-rpms           101 k
 python3-urwid              x86_64        1.3.1-4.el8              rhel-8-for-x86_64-baseos-rpms           783 k
 target-restore             noarch        2.1.71-4.el8             rhel-8-for-x86_64-baseos-rpms            24 k

Transaction Summary
=================================================================================================================
Install  7 Packages
...
Complete!
------------------------

==== Discovering iqns cluster nodes
In which server: [cluster]

Once we have the software installed we need to know which IQN have each of the cluster members. For this we only need to show the content of the initiatorname.iscsi files.

Having created the circle of trust, from str.test.com server we can get the IQN from each server as follow:

[source, bash]
------------------------
for node in ha1 ha2 ha3; do echo -n $node: $(ssh $node cat /etc/iscsi/initiatorname.iscsi); echo; done

ha1: InitiatorName=iqn.1994-05.com.redhat:9b97b0b38c9f
ha2: InitiatorName=iqn.1994-05.com.redhat:9b97b0b38c9e
ha3: InitiatorName=iqn.1994-05.com.redhat:9b97b0b38c9d
------------------------

Take note on this. Every server must have the last hexadecimal part diferent from each other. If not, we have to generate a unique number on this.

==== Configuring ISCSI TARGET
In which server: [str.test.com]

Our str.text.con server have a disk in /dev/sdb which has 16GB in space.

Let's start the targetcli command for configuring the target and which should have access to the shared iscsi volume. 

[source, bash]
------------------------
targetcli
...

/> cd /backstores/block
/backstores/block> create iscsi_shared_storage /dev/sdb
Created block storage object iscsi_shared_storage using /dev/mapper/vdo

/backstores/block> cd /iscsi
/iscsi> create

Created target  iqn.2003-01.org.linux-iscsi.str.x8664:sn.cc4faab82172
Created TPG 1.
Global pref auto_add_default_portal=true
Created default portal listening on all IPs (0.0.0.0), port 3260.

/iscsi> cd iqn.2003-01.org.linux-iscsi.str.x8664:sn.cc4faab82172/tpg1/acls  << Change as per the output of previous command
/iscsi/iqn.20...e18/tpg1/acls> create iqn.1994-05.com.redhat:9b97b0b38c9f  << ha1
Created Node ACL for iqn.1994-05.com.redhat:9b97b0b38c9f
/iscsi/iqn.20...e18/tpg1/acls> create iqn.1994-05.com.redhat:9b97b0b38c9e  << ha2
Created Node ACL for iqn.1994-05.com.redhat:9b97b0b38c9e
/iscsi/iqn.20...e18/tpg1/acls> create iqn.1994-05.com.redhat:9b97b0b38c9d  << ha3
Created Node ACL for iqn.1994-05.com.redhat:9b97b0b38c9d
/iscsi/iqn.20...e18/tpg1/acls> cd /iscsi/iqn.2003-01.org.linux-iscsi.str.x8664:sn.cc4faab82172/tpg1/luns
/iscsi/iqn.20...e18/tpg1/luns> create /backstores/block/iscsi_shared_storage

Created LUN 0.
Created LUN 0->0 mapping in node ACL iqn.1994-05.com.redhat:9b97b0b38c9f
Created LUN 0->0 mapping in node ACL iqn.1994-05.com.redhat:9b97b0b38c9e
Created LUN 0->0 mapping in node ACL iqn.1994-05.com.redhat:9b97b0b38c9d

/iscsi/iqn.20...e18/tpg1/luns> cd /
...
/> saveconfig
Configuration saved to /etc/target/saveconfig.json
/> exit
Global pref auto_save_on_exit=true
Last 10 configs saved in /etc/target/backup/.
Configuration saved to /etc/target/saveconfig.json
------------------------

==== Enabling iscsi services
In which server: [str]

After configuring the target it is time to activate the service as follow:

[source, bash]
------------------------
systemctl enable --now target
systemctl restart target
------------------------

==== Enabling the firewall port 
In which server: [str]

We need to enabling the port that by default pertain to the target service.

[source, bash]
------------------------
firewall-cmd --permanent --add-port=3260/tcp
firewall-cmd --reload
------------------------

So far we only have configured the server which is going to share the disk for the cluster. This could have been a storage array by itself. For the purpose of this excercise the iscsi protocol is enough.

=== Preparing the base for the Cluster

Our next step defines de base of our cluster which will have 3 nodes.

==== Enabling the proper repositories
In which servers: [cluster]

Check in which pool exists HA and resilient storage. Take note of the pool id.

[source, bash]
------------------------
subscription-manager list --available
------------------------

Then attach the corresponding pool and enable the proper repositories. This is needed for install the software required for this exercise.

[source, bash]
------------------------
for node in ha1 ha2 ha3; do
echo ------------------------------
echo Enabling repositories on node $node
ssh $node subscription-manager attach  --pool=8a85f99b727637b201729983324d0540
ssh $node subscription-manager repos --enable=rhel-8-for-x86_64-highavailability-rpms
ssh $node subscription-manager repos --enable=rhel-8-for-x86_64-resilientstorage-rpms
done
------------------------

==== Installing Software
In which servers: [cluster]

[source, bash]
------------------------
for node in ha1 ha2 ha3; do
echo ------------------------------
echo Installing software on node $node
ssh $node yum install -y pcs fence-agents-all pcp-zeroconf iscsi-initiator-utils lvm2-lockd gfs2-utils dlm
echo
done
------------------------

==== Enabling the Firewall
In which servers: [cluster]

[source, bash]
------------------------
for node in ha1 ha2 ha3; do 
echo Setting firewall on $node 
ssh $node systemctl enable --now firewalld 
ssh $node firewall-cmd --permanent --add-service=high-availability 
ssh $node firewall-cmd --add-service=high-availability 
ssh $node firewall-cmd --reload 
done
------------------------

Then we can check is the ha service is enabled.

[source, bash]
------------------------
for node in ha1 ha2 ha3; do
echo Services enabled on $node: $(ssh $node firewall-cmd --list-services)
done

Services enabled on ha1: cockpit dhcpv6-client high-availability ssh
Services enabled on ha2: cockpit dhcpv6-client high-availability ssh
Services enabled on ha3: cockpit dhcpv6-client high-availability ssh
------------------------

==== Set password for hacluster user
In which servers: [cluster]

We must define a password for administering the cluster with the hacluster user. For this exercise I am assigning "ltodemos" como password.

[source, bash]
------------------------
for node in ha1 ha2 ha3; do
echo Enter the password for $node
ssh $node passwd hacluster
echo
done
------------------------

==== Configuring the Cluster Service to be enabled and starts automatically at boot
In which servers: [cluster]

[source, bash]
------------------------
for node in ha1 ha2 ha3; do
echo enabling pcsd on $node
ssh $node systemctl enable --now pcsd
echo
done
------------------------

Then check the service on each node.

[source, bash]
------------------------
for node in ha1 ha2 ha3; do
echo $node ----------------
ssh $node systemctl status pcsd | sed ''/active/s//$(printf "\033[32mactive\033[0m")/''
echo
done
------------------------

=== Creating a high availability cluster

At this point we have installed the cluster software and enabled all the services needed for what comes next. We are going to create the cluster itself with the 3 nodes.

From now on, we are going to use cluster commands like "pcs" which only need to be issued from one of the cluster members.

==== Authenticating the pcs user hacluster for each node
In which servers: [ha1.test.com]

Use the password ltodemos configured in previous steps.

[source, bash]
------------------------
pcs host auth ha1.test.com ha2.test.com ha3.test.com -u hacluster -p ltodemos

ha1.test.com: Authorized
ha2.test.com: Authorized
ha3.test.com: Authorized
------------------------

==== Creating the 3-node cluster named "cluster"
In which servers: [ha1]

[source, bash]
------------------------
pcs cluster setup ha_cluster --start ha1.test.com ha2.test.com ha3.test.com

No addresses specified for host 'ha1.test.com', using 'ha1.test.com'
No addresses specified for host 'ha2.test.com', using 'ha2.test.com'
No addresses specified for host 'ha3.test.com', using 'ha3.test.com'
Destroying cluster on hosts: 'ha1.test.com', 'ha2.test.com', 'ha3.test.com'...
ha1.test.com: Successfully destroyed cluster
ha2.test.com: Successfully destroyed cluster
ha3.test.com: Successfully destroyed cluster
Requesting remove 'pcsd settings' from 'ha1.test.com', 'ha2.test.com', 'ha3.test.com'
ha1.test.com: successful removal of the file 'pcsd settings'
ha2.test.com: successful removal of the file 'pcsd settings'
ha3.test.com: successful removal of the file 'pcsd settings'
Sending 'corosync authkey', 'pacemaker authkey' to 'ha1.test.com', 'ha2.test.com', 'ha3.test.com'
ha2.test.com: successful distribution of the file 'corosync authkey'
ha2.test.com: successful distribution of the file 'pacemaker authkey'
ha3.test.com: successful distribution of the file 'corosync authkey'
ha3.test.com: successful distribution of the file 'pacemaker authkey'
ha1.test.com: successful distribution of the file 'corosync authkey'
ha1.test.com: successful distribution of the file 'pacemaker authkey'
Sending 'corosync.conf' to 'ha1.test.com', 'ha2.test.com', 'ha3.test.com'
ha1.test.com: successful distribution of the file 'corosync.conf'
ha2.test.com: successful distribution of the file 'corosync.conf'
ha3.test.com: successful distribution of the file 'corosync.conf'
Cluster has been successfully set up.
Starting cluster on hosts: 'ha1.test.com', 'ha2.test.com', 'ha3.test.com'...
------------------------

==== Enabling the cluster to start on boot
In which servers: [ha1]

[source, bash]
------------------------
pcs cluster enable --all

ha1.test.com: Cluster Enabled
ha2.test.com: Cluster Enabled
ha3.test.com: Cluster Enabled
------------------------

==== Checking the configuration so far

Let´s see if everything is working as expected.

[source, bash]
------------------------
pcs status | sed ''/active/s//$(printf "\033[32mactive\033[0m")/''

Cluster name: ha_cluster

WARNINGS:
No stonith devices and stonith-enabled is not false

Cluster Summary:
  * Stack: corosync
  * Current DC: ha1.test.com (version 2.0.3-5.el8_2.1-4b1f869f0f) - partition with quorum
  * Last updated: Wed Oct 21 10:39:33 2020
  * Last change:  Wed Oct 21 10:38:23 2020 by hacluster via crmd on ha1.test.com
  * 3 nodes configured
  * 0 resource instances configured

Node List:
  * Online: [ ha1.test.com ha2.test.com ha3.test.com ]

Full List of Resources:
  * No resources

Daemon Status:
  corosync: active/enabled
  pacemaker: active/enabled
  pcsd: active/enabled

------------------------

Look at the sed part of the of the pcs command. This is only to show the "active" work in green. As we can see, corosync, pacemaker and pcsd are active.

=== Configuring a shared storage in the cluster

For the purpose of this exercise, we are going to use the iscsi server to present a common volume to all 3 nodes that are going to be members of the cluster that we just built. 

In this volume all nodes will have the possibility to read and write in sync and controlled by the cluster.

==== Configuring iscsi in all nodes
In which servers: [cluster]

You can execute this from any server. 

[source, bash]
------------------------
for node in ha1 ha2 ha3; do
echo Setting iscsi volume on node $node
ssh $node iscsiadm -m discovery -t sendtargets -p str.test.com
ssh $node iscsiadm -m node -L automatic
echo
done

Setting iscsi volume on node ha1
192.168.56.157:3260,1 iqn.2003-01.org.linux-iscsi.str.x8664:sn.cc4faab82172
Logging in to [iface: default, target: iqn.2003-01.org.linux-iscsi.str.x8664:sn.cc4faab82172, portal: 192.168.56.157,3260]
Login to [iface: default, target: iqn.2003-01.org.linux-iscsi.str.x8664:sn.cc4faab82172, portal: 192.168.56.157,3260] successful.

Setting iscsi volume on node ha2
192.168.56.157:3260,1 iqn.2003-01.org.linux-iscsi.str.x8664:sn.cc4faab82172
Logging in to [iface: default, target: iqn.2003-01.org.linux-iscsi.str.x8664:sn.cc4faab82172, portal: 192.168.56.157,3260]
Login to [iface: default, target: iqn.2003-01.org.linux-iscsi.str.x8664:sn.cc4faab82172, portal: 192.168.56.157,3260] successful.

Setting iscsi volume on node ha3
192.168.56.157:3260,1 iqn.2003-01.org.linux-iscsi.str.x8664:sn.cc4faab82172
Logging in to [iface: default, target: iqn.2003-01.org.linux-iscsi.str.x8664:sn.cc4faab82172, portal: 192.168.56.157,3260]
Login to [iface: default, target: iqn.2003-01.org.linux-iscsi.str.x8664:sn.cc4faab82172, portal: 192.168.56.157,3260] successful.
------------------------

==== Check for the disks presented in each node

[source, bash]
------------------------
for node in ha1 ha2 ha3; do
echo node $node: $(ssh $node lsblk | grep sdb)
done

node ha1: sdb 8:16 0 16G 0 disk
node ha2: sdb 8:16 0 16G 0 disk
node ha3: sdb 8:16 0 16G 0 disk
------------------------

==== Configuring Shut The Other Node In The Head (STONITH)
In which servers: [ha1]

The iscsi target has been mapped on /dev/sdb and in this exercise is 16G size.

[source, bash]
------------------------
pcs stonith create scsi-shooter fence_scsi pcmk_host_list="ha1.test.com ha2.test.com ha3.test.com" devices=/dev/sdb  meta provides=unfencing
pcs property set stonith-enabled=true
pcs property set no-quorum-policy=freeze
------------------------

==== Create and clone the locking resource
In which servers: [ha1]

[source, bash]
------------------------
pcs resource create dlm --group locking ocf:pacemaker:controld op monitor interval=30s on-fail=fence
pcs resource clone locking interleave=true
------------------------

==== Setting up lvmlockd resource
In which servers: [ha1]

[source, bash]
------------------------
pcs resource create lvmlockd --group locking ocf:heartbeat:lvmlockd op monitor interval=30s on-fail=fence
------------------------

==== Let's check the status of the cluster
pcs status --full

=== Volume Group Creation
In which servers: [ha1]

[source, bash]
------------------------
vgcreate --shared shared_vg1 /dev/sdb

Physical volume "/dev/sdb" successfully created.
Volume group "shared_vg1" successfully created
VG shared_vg1 starting dlm lockspace
Starting locking.  Waiting until locks are ready...
------------------------

=== Starting the locking mechanism in the rest of the servers
In which servers: [ha2 ha3]

[source, bash]
------------------------
for node in ha2 ha3; do
echo node $node: $(ssh $node vgchange --lock-start shared_vg1)
done
------------------------

=== Checking what we have done so far
In which servers: [ha1]

We can seek the lvmlockd started in the 3 nodes.

[source, bash]
------------------------
pcs status --full


Cluster name: ha_cluster
Cluster Summary:
  * Stack: corosync
  * Current DC: ha1.test.com (1) (version 2.0.3-5.el8_2.1-4b1f869f0f) - partition with quorum
  * Last updated: Wed Oct 21 13:47:47 2020
  * Last change:  Wed Oct 21 13:41:12 2020 by root via cibadmin on ha1.test.com
  * 3 nodes configured
  * 7 resource instances configured

Node List:
  * Online: [ ha1.test.com (1) ha2.test.com (2) ha3.test.com (3) ]

Full List of Resources:
  * scsi-shooter        (stonith:fence_scsi):   Started ha1.test.com
  * Clone Set: locking-clone [locking]:
    * Resource Group: locking:0:
      * dlm     (ocf::pacemaker:controld):      Started ha1.test.com
      * lvmlockd        (ocf::heartbeat:lvmlockd):      Started ha1.test.com
    * Resource Group: locking:1:
      * dlm     (ocf::pacemaker:controld):      Started ha2.test.com
      * lvmlockd        (ocf::heartbeat:lvmlockd):      Started ha2.test.com
    * Resource Group: locking:2:
      * dlm     (ocf::pacemaker:controld):      Started ha3.test.com
      * lvmlockd        (ocf::heartbeat:lvmlockd):      Started ha3.test.com
    * Started: [ ha1.test.com ha2.test.com ha3.test.com ]

Migration Summary:

Fencing History:
  * unfencing of ha3.test.com successful: delegate=ha3.test.com, client=pacemaker-controld.10269, origin=ha1.test.com, completed='2020-10-21 13:31:49 -05:00'
  * unfencing of ha1.test.com successful: delegate=ha1.test.com, client=pacemaker-controld.10269, origin=ha1.test.com, completed='2020-10-21 13:31:48 -05:00'
  * unfencing of ha2.test.com successful: delegate=ha2.test.com, client=pacemaker-controld.10269, origin=ha1.test.com, completed='2020-10-21 13:31:48 -05:00'

Tickets:

PCSD Status:
  ha1.test.com: Online
  ha2.test.com: Online
  ha3.test.com: Online

Daemon Status:
  corosync: active/enabled
  pacemaker: active/enabled
  pcsd: active/enabled
------------------------

==== Creating a logical volume on shared_vg1 called shared_lv1
In which servers: [ha1]

Now it is time to create the logical volume wich is going to be mounted in each node for hosting data. This volume is going to be configured with 10G, so we can have the option of growing in later time.

[source, bash]
------------------------
lvcreate --activate sy -L10G -n shared_lv1 shared_vg1
------------------------

=== Creating the filesystem on the logical volume
In which servers: [ha1]

[source, bash]
------------------------
mkfs.gfs2 -j3 -p lock_dlm -t ha_cluster:data /dev/shared_vg1/shared_lv1

/dev/shared_vg1/shared_lv1 is a symbolic link to /dev/dm-2
This will destroy any data on /dev/dm-2
Are you sure you want to proceed? [y/n] y
Discarding device contents (may take a while on large devices): Done
Adding journals: Done
Building resource groups: Done
Creating quota file: Done
Writing superblock and syncing: Done
Device:                    /dev/shared_vg1/shared_lv1
Block size:                4096
Device size:               10.00 GB (2621440 blocks)
Filesystem size:           10.00 GB (2621437 blocks)
Journals:                  3
Journal size:              32MB
Resource groups:           43
Locking protocol:          "lock_dlm"
Lock table:                "ha_cluster:data"
UUID:                      1fee69d3-6ef5-4c8f-995b-ed682b3270a3
------------------------

*how to check the cluster name
pcs property list cluster-name

==== Creating the shared filesystem resource
In which servers: [ha1]

Having the volume group and logical volume created on ha1.test.com server, we now need to create the resource responsible for mounting the logical volume as a functional disk in each node.

[source, bash]
------------------------
pcs resource create sharedlv1 --group shared_vg1 ocf:heartbeat:LVM-activate lvname=shared_lv1 vgname=shared_vg1 \
activation_mode=shared vg_access_mode=lvmlockd
------------------------

The resource is going to be started on any node... we need to clone the resource so all nodes have the resource started.

[source, bash]
------------------------
pcs resource clone shared_vg1 interleave=true
[source, bash]
------------------------

==== Configuring the order in which the resource starts. 
In which servers: [ha1]

We need make this resource to be started at first.

[source, bash]
------------------------
pcs constraint order start locking-clone then shared_vg1-clone

Adding locking-clone shared_vg1-clone (kind: Mandatory) (Options: first-action=start then-action=start)
------------------------

Also we need to start the volume group resource group in the same node as the locking resource group.

[source, bash]
------------------------
pcs constraint colocation add shared_vg1-clone with locking-clone
------------------------

==== Check logical volumes on all nodes
In which servers: [cluster]

[source, bash]
------------------------
for node in ha1 ha2 ha3; do
echo ------------------------------
echo node $node
ssh $node lvs
echo
done
------------------------
 
==== Creating the Resource for automatically mount the filesystem in all nodes
In which servers: [ha1]

So far the logical volume can be seen from all nodes. Now we need to creaate a resource for mounting the volume in the /data directory.

[source, bash]
------------------------
pcs resource create sharedfs1 --group shared_vg1 ocf:heartbeat:Filesystem device="/dev/shared_vg1/shared_lv1" directory="/data" fstype="gfs2" options=noatime op monitor interval=10s on-fail=fence
------------------------

==== Check the status of the configuracion
In which servers: [ha1]


[source, bash]
------------------------
pcs status --full

Cluster name: ha_cluster
Cluster Summary:
  * Stack: corosync
  * Current DC: ha1.test.com (1) (version 2.0.3-5.el8_2.1-4b1f869f0f) - partition with quorum
  * Last updated: Wed Oct 21 14:11:35 2020
  * Last change:  Wed Oct 21 14:11:28 2020 by root via cibadmin on ha1.test.com
  * 3 nodes configured
  * 13 resource instances configured

Node List:
  * Online: [ ha1.test.com (1) ha2.test.com (2) ha3.test.com (3) ]

Full List of Resources:
  * scsi-shooter        (stonith:fence_scsi):   Started ha1.test.com
  * Clone Set: locking-clone [locking]:
    * Resource Group: locking:0:
      * dlm     (ocf::pacemaker:controld):      Started ha1.test.com
      * lvmlockd        (ocf::heartbeat:lvmlockd):      Started ha1.test.com
    * Resource Group: locking:1:
      * dlm     (ocf::pacemaker:controld):      Started ha2.test.com
      * lvmlockd        (ocf::heartbeat:lvmlockd):      Started ha2.test.com
    * Resource Group: locking:2:
      * dlm     (ocf::pacemaker:controld):      Started ha3.test.com
      * lvmlockd        (ocf::heartbeat:lvmlockd):      Started ha3.test.com
    * Started: [ ha1.test.com ha2.test.com ha3.test.com ]
  * Clone Set: shared_vg1-clone [shared_vg1]:
    * Resource Group: shared_vg1:0:
      * sharedlv1       (ocf::heartbeat:LVM-activate):  Started ha1.test.com
      * sharedfs1       (ocf::heartbeat:Filesystem):    Started ha1.test.com
    * Resource Group: shared_vg1:1:
      * sharedlv1       (ocf::heartbeat:LVM-activate):  Started ha2.test.com
      * sharedfs1       (ocf::heartbeat:Filesystem):    Started ha2.test.com
    * Resource Group: shared_vg1:2:
      * sharedlv1       (ocf::heartbeat:LVM-activate):  Started ha3.test.com
      * sharedfs1       (ocf::heartbeat:Filesystem):    Started ha3.test.com
    * Started: [ ha1.test.com ha2.test.com ha3.test.com ]

Migration Summary:

Fencing History:
  * unfencing of ha3.test.com successful: delegate=ha3.test.com, client=pacemaker-controld.10269, origin=ha1.test.com, completed='2020-10-21 13:31:49 -05:00'
  * unfencing of ha1.test.com successful: delegate=ha1.test.com, client=pacemaker-controld.10269, origin=ha1.test.com, completed='2020-10-21 13:31:48 -05:00'
  * unfencing of ha2.test.com successful: delegate=ha2.test.com, client=pacemaker-controld.10269, origin=ha1.test.com, completed='2020-10-21 13:31:48 -05:00'

Tickets:

PCSD Status:
  ha1.test.com: Online
  ha2.test.com: Online
  ha3.test.com: Online

Daemon Status:
  corosync: active/enabled
  pacemaker: active/enabled
  pcsd: active/enabled
------------------------


==== Checking all servers have mounted the filesystem on /data
In which servers: [cluster]

[source, bash]
------------------------
for node in ha1 ha2 ha3; do
echo ------------------------------
echo node $node
ssh $node df -kh | grep data
echo
done

------------------------------
node ha1
/dev/mapper/shared_vg1-shared_lv1   10G  100M   10G   1% /data
------------------------------
node ha2
/dev/mapper/shared_vg1-shared_lv1   10G  100M   10G   1% /data
------------------------------
node ha3
/dev/mapper/shared_vg1-shared_lv1   10G  100M   10G   1% /data
------------------------

=== Creating a Web server in High Availability

Now that we have our storage ready to be used is time to create the resources required to have Apache in HA. 

==== Installing Apache
In which servers: [cluster]

[source, bash]
------------------------
for node in ha1 ha2 ha3; do
echo ------------------------------
echo Installing apache on node $node
ssh $node yum -y install httpd wget
echo
done
------------------------------

Then in each node add the following selector in /etc/httpd/conf/httpd.conf.

[source, bash]
------------------------
ssh ha1 

cat <<EOF >> /etc/httpd/conf/httpd.conf
<Location /server-status>
    SetHandler server-status
    Require local
</Location>
EOF

ssh ha2
...
------------------------

When we use the apache resource agent to manage Apache, it does not use systemd. Because of this, you must edit the logrotate script supplied with Apache so that it does not use systemctl to reload Apache.

Remove the following line in the /etc/logrotate.d/httpd file on each node in the cluster.

[source, bash]
------------------------
/bin/systemctl reload httpd.service > /dev/null 2>/dev/null || true
------------------------

Replace the line you removed with the following three lines.

[source, bash]
------------------------
/usr/bin/test -f /var/run/httpd.pid >/dev/null 2>/dev/null &&
/usr/bin/ps -q /usr/bin/cat /var/run/httpd.pid >/dev/null 2>/dev/null &&
/usr/sbin/httpd -f /etc/httpd/conf/httpd.conf -c "PidFile /var/run/httpd.pid" -k graceful > /dev/null 2>/dev/null || true
------------------------

Now let´s replace the default root directory that apache use in each node.

[source, bash]
------------------------
for node in ha1 ha2 ha3; do 
echo Changing Apache Root Directory on node $node; 
ssh $node cp /etc/httpd/conf/httpd.conf /etc/httpd/conf/httpd.conf.bck; 
ssh "$node" 'sed -i "s/\/var\/www/\/data\/www/g" /etc/httpd/conf/httpd.conf.bck' > /etc/httpd/conf/httpd.conf; 
done
------------------------

After change the root directory is time to create some directories in the new /data directory.
[source, bash]
------------------------
mkdir /data/www/html
mkdir /data/www/cgi-bin
mkdir /data/www/error
restorecon -R /data/www
------------------------

Now create a simple web page.

[source, bash]
------------------------
cat <<EOF >/data/www/html/index.html
<html>
<body>Hello</body>
</html>
EOF
------------------------

shared_vg1
pcs resource create VirtualIP IPaddr2 ip=192.168.56.170 \
cidr_netmask=24 --group shared_vg1

