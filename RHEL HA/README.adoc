:scrollbar:
:data-uri:
:toc2:
:imagesdir: images

= High Availability add-on on RHEL - LTO Show & Tell Series

== Description
This Show&Tell is aimed to share some of the most important concepts and features of the High Availability posibilities RHEL propose.

Audience: IT Managers, Architects and technical staff who operates Linux

:numbered:

== Introduction

The High Availability Add-On is a clustered system that provides reliability, scalability, and availability to critical production services.

A cluster is two or more computers (called nodes or members) that work together to perform a task. Clusters can be used to provide highly available services or resources. The redundancy of multiple machines is used to guard against failures of many types.

== Components

Mayor components are listed below:

* Cluster infrastructure — Provides fundamental functions for nodes to work together as a cluster: configuration file management, membership management, lock management, and fencing.
* High availability service management — Provides failover of services from one cluster node to another in case a node becomes inoperative.
* Cluster administration tools — Configuration and management tools for setting up, configuring, and managing the High Availability Add-On. The tools are for use with the cluster infrastructure components, the high availability and service management components, and storage.

Some supplements can be used for the High Availability Add-On with the following components:

* Red Hat GFS2 (Global File System 2) — Part of the Resilient Storage Add-On, this provides a cluster file system for use with the High Availability Add-On. GFS2 allows multiple nodes to share storage at a block level as if the storage were connected locally to each cluster node. GFS2 cluster file system requires a cluster infrastructure.
* LVM Locking Daemon (lvmlockd) — Part of the Resilient Storage Add-On, this provides volume management of cluster storage. lvmlockd support also requires cluster infrastructure.
* Load Balancer Add-On — Routing software that provides high availability load balancing and failover in layer 4 (TCP) and layer 7 (HTTP, HTTPS) services. The Load Balancer Add-On runs in a cluster of redundant virtual routers that uses load algorithms to distribute client requests to real servers, collectively acting as a virtual server. It is not necessary to use the Load Balancer Add-On in conjunction with Pacemaker.

== Pacemaker

Pacemaker is a cluster resource manager. It achieves maximum availability for your cluster services and resources by making use of the cluster infrastructure’s messaging and membership capabilities to deter and recover from node and resource-level failure.

=== Pacemaker components

* Cluster Information Base (CIB)
The Pacemaker information daemon, which uses XML internally to distribute and synchronize current configuration and status information from the Designated Coordinator (DC) — a node assigned by Pacemaker to store and distribute cluster state and actions by means of the CIB — to all other cluster nodes.

* Cluster Resource Management Daemon (CRMd)
Pacemaker cluster resource actions are routed through this daemon. Resources managed by CRMd can be queried by client systems, moved, instantiated, and changed when needed.

Each cluster node also includes a local resource manager daemon (LRMd) that acts as an interface between CRMd and resources. LRMd passes commands from CRMd to agents, such as starting and stopping and relaying status information.

* Shoot the Other Node in the Head (STONITH)
STONITH is the Pacemaker fencing implementation. It acts as a cluster resource in Pacemaker that processes fence requests, forcefully shutting down nodes and removing them from the cluster to ensure data integrity. STONITH is configured in the CIB and can be monitored as a normal cluster resource. 

* corosync
corosync is the component - and a daemon of the same name - that serves the core membership and member-communication needs for high availability clusters. It is required for the High Availability Add-On to function.

Other corosync functions are:

- Manages quorum rules and determination.
- Provides messaging capabilities for applications that coordinate or operate across multiple members of the cluster and thus must communicate stateful or other information - between instances.
- Uses the kronosnet library as its network transport to provide multiple redundant links and automatic failover.

== The fencing mechanism

If communication with a single node in the cluster fails, then other nodes in the cluster must be able to restrict or release access to resources that the failed cluster node may have access to. Because the node itself may not be responsive this cannot be accomplished by contacting the cluster failed node. Instead, we must provide an external method, which is called fencing with a fence agent. A fence device is an external device that can be used by the cluster to restrict access to shared resources by an errant node, or to issue a hard reboot on the cluster node.

== The Quorum Mechanism

In order to maintain cluster integrity and availability, cluster systems use a concept known as quorum to prevent data corruption and loss. A cluster has quorum when more than half of the cluster nodes are online. To mitigate the chance of data corruption due to failure, Pacemaker by default stops all resources if the cluster does not have quorum.

Quorum is established using a voting system. When a cluster node does not function as it should or loses communication with the rest of the cluster, the majority working nodes can vote to isolate and, if needed, fence the node for servicing.

The quorum features in Pacemaker prevent what is also known as split-brain, a phenomenon where the cluster is separated from communication but each part continues working as separate clusters, potentially writing to the same data and possibly causing corruption or loss. 

A Red Hat Enterprise Linux High Availability Add-On cluster uses the votequorum service, in conjunction with fencing, to avoid split brain situations. A number of votes is assigned to each system in the cluster, and cluster operations are allowed to proceed only when a majority of votes is present.

== What is a Resource?

An instance of program, data, or application to be managed by the cluster service is called A cluster resource. Agents abtracts these resources providing a standard interface for managing the resource in a cluster environment.

We can add monitoring operations to a resource’s definition to ensure that resources remain healthy. 

The behavior of a resource in a cluster can be determined by configuring constraints. 

* location constraints — A location constraint determines which nodes a resource can run on.
* ordering constraints — An ordering constraint determines the order in which the resources run.
* colocation constraints — A colocation constraint determines where resources will be placed relative to other resources.

Also, groups can be configured for setting resources that need to be located together, start sequentially, and stop in the reverse order.

* Logical volumes 

The Red Hat High Availability Add-On provides support for LVM volumes in two distinct cluster configurations:

* High availability LVM volumes (HA-LVM) in active/passive failover configurations in which only a single node of the cluster accesses the storage at any one time.
* LVM volumes that use the lvmlockd daemon to manage storage devices in active/active configurations in which more than one node of the cluster requires access to the storage at the same time. The lvmlockd daemon is part of the Resilient Storage Add-On.

== A general diagram of a cluster implemented



--------------------------- DRAFT

Let's assume also the following convention.

Nodes:
ha1.test.com -> node 1
ha2.test.com -> node 2
ha3.test.com- > node 3
str.test.com -> iscsi target

All commands are in red and italics.
All text result of command are in green and italics

------------------------------------------
A) Configure the iscsi target server

1) Install SW
In which server: [str.test.com]

yum install -y targetcli

2) Discover iqns cluster nodes
In which server: [ALL]

cat /etc/iscsi/initiatorname.iscsi

InitiatorName=iqn.1994-05.com.redhat:xxxxxxxxxxxxxxxxxx

take note on this. Every server must have the "xxxxxxxxxxxxxxx" part diferent from each other. If not, we have to generate a unique number on this.

3) Configure ISCSI TARGET
In which server: [str]

Let's assume we have create a disk using whichever method called /dev/mapper/vdo which has 128GB in space

targetcli
...

/> cd /backstores/block
/backstores/block> create iscsi_shared_storage /dev/mapper/vdo
Created block storage object iscsi_shared_storage using /dev/mapper/vdo

/backstores/block> cd /iscsi
/iscsi> create

Created target iqn.2003-01.org.linux-iscsi.storage.x8664:sn.aaaaaaaaaaaaaaaaaaa.
Created TPG 1.
Global pref auto_add_default_portal=true
Created default portal listening on all IPs (0.0.0.0), port 3260.

/iscsi> cd iqn.2003-01.org.linux-iscsi.storage.x8664:sn.aaaaaaaaaaaaaaaaaaa/tpg1/acls  << Change as per the output of previous command
/iscsi/iqn.20...e18/tpg1/acls> create iqn.1994-05.com.redhat:111111111111111111  << ha1
Created Node ACL for iqn.1994-05.com.redhat:11111111111111111111111
/iscsi/iqn.20...e18/tpg1/acls> create iqn.1994-05.com.redhat:2222222222222222  << ha2
Created Node ACL for iqn.1994-05.com.redhat:22222222222222222222
/iscsi/iqn.20...e18/tpg1/acls> create iqn.1994-05.com.redhat:3333333333333333  << ha3
Created Node ACL for iqn.1994-05.com.redhat:33333333333333333333

/iscsi/iqn.20...e18/tpg1/acls> cd /iscsi/iqn.2003-01.org.linux-iscsi.storage.x8664:sn.aaaaaaaaaaaaaaaaaaa/tpg1/luns
/iscsi/iqn.20...e18/tpg1/luns> create /backstores/block/iscsi_shared_storage

Created LUN 0.
Created LUN 0->0 mapping in node ACL iqn.1994-05.com.redhat:1111111111111111111111
Created LUN 0->0 mapping in node ACL iqn.1994-05.com.redhat:2222222222222222222222
Created LUN 0->0 mapping in node ACL iqn.1994-05.com.redhat:3333333333333333333333

/iscsi/iqn.20...e18/tpg1/luns> cd /
...
/> saveconfig
Configuration saved to /etc/target/saveconfig.json
/> exit
Global pref auto_save_on_exit=true
Last 10 configs saved in /etc/target/backup/.
Configuration saved to /etc/target/saveconfig.json

4) Enable iscsi services
In which server: [str]

systemctl enable --now target
systemctl restart target

5) Enable firewall
In which server: [str]

firewall-cmd --permanent --add-port=3260/tcp
firewall-cmd --reload


-------------------------------------------
B) Prepare the base for the Cluster


1) Define the naming convention in /etc/hosts
In which nodes: [ALL]

Change the IPs by how your servers are configured

192.168.56.154 ha1.test.com ha1
192.168.56.160 ha2.test.com ha2
192.168.56.159 ha3.test.com ha3
192.168.56.157 str.test.com str

2) Create Trust among Servers
In which servers: [ALL]

ssh-keygen
ssh-copy-id ha1
ssh-copy-id ha2
ssh-copy-id ha3
ssh-copy-id str

3) Enabling repositories

In which servers: [ALL]
subscription-manager list --available
subscription-manager attach  --pool= "the pool which contains HA and resiliente storage"

subscription-manager repos --enable=rhel-8-for-x86_64-highavailability-rpms
subscription-manager repos --enable=rhel-8-for-x86_64-resilientstorage-rpms

4) Install SW
In which servers: [ALL]

yum install -y pcs fence-agents-all pcp-zeroconf
yum -y install iscsi-initiator-utils
yum install -y lvm2-lockd gfs2-utils dlm

5) Enable Firewall
In which servers: [ALL]

firewall-cmd --permanent --add-service=high-availability
firewall-cmd --add-service=high-availability
firewall-cmd --reload

6) Set password for hacluster user
In which servers: [ALL]
passwd hacluster

7) Start Cluster Service
In which servers: [ALL]

systemctl enable --now pcsd


-----------------------------------------------
C) Creating a high availability cluster

1) Authenticate the pcs user hacluster for each node
In which servers: [ha1]

pcs host auth ha1.test.com ha2.test.com ha3.test.com -u hacluster -p youpassword

2) Creating the 3-node cluster named "cluster"
In which servers: [ha1]

pcs cluster setup ha_cluster --start ha1.test.com ha2.test.com ha3.test.com

3) Enable the cluster to start on boot
In which servers: [ha1]

pcs cluster enable --all

4) Check the configuration so far

pcs status

------------------------------------
D) Configure the shared storage in the cluster

1) Configure iscsi in all nodes
In which servers: [ALL]

iscsiadm -m discovery -t sendtargets -p str
iscsiadm -m node -L automatic

2) Configure Stonish
In which servers: [ha1]

The iscsi target has been mapped on /dev/sdb and in this lab is 128G length

pcs stonith create scsi-shooter fence_scsi pcmk_host_list="ha1.test.com ha2.test.com ha3.test.com" devices=/dev/sdb  meta provides=unfencing

ssh $i pcs property set stonith-enabled=true; \
ssh $i pcs property set no-quorum-policy=freeze; \

3) Create and clone the lockinf resource
In which servers: [ha1]

pcs resource create dlm --group locking ocf:pacemaker:controld op monitor interval=30s on-fail=fence
pcs resource clone locking interleave=true

pcs status --full

4) Create a Volume Group
In which servers: [ha1]

vgcreate --shared shared_vg1 /dev/sdb

5) Start the locking in the rest of the servers
In which servers: [ha2 ha3]

vgchange --lock-start shared_vg1

6) Create a logical volume on shared_vg1 called shared_lv1
In which servers: [h1]

lvcreate --activate sy -L30G -n shared_lv1 shared_vg1

7) Create the filesystem on the logical volume
In which servers: [ha1]

mkfs.gfs2 -j3 -p lock_dlm -t ha_cluster:data /dev/shared_vg1/shared_lv1

*how to check the cluster name
pcs property list cluster-name

8) Create the shared filesystem resource
In which servers: [ha1]

pcs resource create sharedlv1 --group shared_vg1 ocf:heartbeat:LVM-activate lvname=shared_lv1 vgname=shared_vg1 \
activation_mode=shared vg_access_mode=lvmlockd

pcs resource clone shared_vg1 interleave=true

pcs constraint order start locking-clone then shared_vg1-clone

pcs constraint colocation add shared_vg1-clone with locking-clone

9) Check logical volumes on all nodes
In which servers: [All]

lvs

  LV         VG         Attr       LSize  Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
  root       rhel       -wi-ao---- 13.39g
  swap       rhel       -wi-ao----  1.60g
  shared_lv1 shared_vg1 -wi-ao---- 30.00g
 
10) Create the Resource for automatically mount the filesystem in all nodes
In which servers: [ha1]

pcs resource create sharedfs1 --group shared_vg1 ocf:heartbeat:Filesystem device="/dev/shared_vg1/shared_lv1" directory="/data" fstype="gfs2" options=noatime op monitor interval=10s on-fail=fence

11) Check the status of the configuracion
In which servers: [ha1]

pcs status --full


12) Check all servers have mounted the filesystem on /data
In which servers: [ALL]

df -kh | grep data
